---
title: "The Betlab Project"
author: "Tobsen1x"
date: "Tuesday, December 09, 2014"
output: pdf_document
---

## Abstract

The Betlab Project aims to predict the outcome of football matches. The predictions are compared with booky odds to place value bets. To predict the outcome, the market prices of the participating players are analysed because they are assumed to represent the base quality of a player. The market prices are determined two times a year, so there is a need to integrate a short term form quantifier for each participating player. These data is provided by a german football magazin and is called kicker grade, which is a school grade evaluating every performance of the participating players.

## Data

The data is collected from several websites, a Java application is written to grab them and write them into a relational database. These parser are not part of this report.

### Datasets

stats -> an observation contains information for one player in one match
matches -> contains all matches  
odds -> contains booky odds and probabilies for all matches

```{r warning=FALSE, message=FALSE, cache=TRUE}
source(file = 'loadData.R', echo = FALSE, encoding = 'UTF-8') 
data <- loadData('BL1')
stats <- data$playerStats
matches <- data$matches
odds <- data$odds
```

The **stats** dataset contains `r nrow(stats)` observations with `r ncol(stats)` variables. The most important variables are:  

- matchId: Id of the match  
- playerId: Id of the player  
- kickerGrade: school grade evaluating the performance of the player  
- transPos: position the player takes in the regarding match  
- home: is the regarding player playing at home  
- fitPrice: youngest marketprice of the regarding player before the match  
  
```{r warning=FALSE, message=FALSE}
library(dplyr)
summary(select(stats, kickerGrade, transPos, playerAssignment, fitPrice))
```

The **matches** dataset contains `r nrow(matches)` matches from `r length(unique(matches$league))` leagues in the seasons `r min(matches$season)` to `r max(matches$season)`.

The **odds** dataset contains booky odds for `r nrow(odds)` matches.

## Enrich stats by adjusted grade

The function enrichAdjGrade in the script adjGradeModel.R enriches stats by an adjusted grade which represents the pure form of a player in a match. That means the kicker grade is purged by the the players position, the quality of the opponents players, the home advantage and the quality of the regarded player. The goal is to extract a player predictor which represents solely the player form, independent of the mentioned properties.

```{r warning=FALSE, message=FALSE, cache=TRUE}
source(file = 'adjGradeModel.R', echo = FALSE, encoding = 'UTF-8')
# enriches stats with the opponent price
adjGradeData <- extractFeaturesForAdjGradeModel(stats)
library(magrittr)
# select just the variables necessary for modelling
modelData <- adjGradeData %>% select(kickerGrade, fitPrice, 
                                     opponentPrice, home, transPos)
library(e1071)
# Checking for skewness in numeric predictors
modelData %>% select(fitPrice, opponentPrice) %>% apply(2, skewness)
```

Both predictors are skewed (> 1), so a BoxCox transformation is used. Both predictors are centered and scaled, too.

```{r warning=FALSE, message=FALSE}
library(caret)
# BoxCox Transformation to resolve skewness
preProc <- modelData %>% select(fitPrice, opponentPrice) %>% 
    preProcess(method = c('center', 'scale', "BoxCox"))
preProcPredictors <-  preProc %>% predict(select(modelData, fitPrice, opponentPrice))
preProcPredictors <- preProcPredictors %>% rename(preProcFitPrice = fitPrice, preProcOpponentPrice = opponentPrice)
# attach preprocessed predictors
modelData <- modelData %>% cbind(preProcPredictors)

library(ggplot2)
# Plot to visualize the relationship of the poredictors to the outcome
modelData %>% ggplot(aes(y = kickerGrade)) +
    geom_smooth(aes(x = preProcFitPrice, colour = 'preProcFitPrice')) +
    geom_smooth(aes(x = preProcOpponentPrice, 
                    colour = 'preProcOpponentPrice')) +
    scale_x_continuous(name = element_blank()) +
    scale_colour_discrete(name  = element_blank(),
                          breaks=c("preProcFitPrice", "preProcOpponentPrice"),
                          labels=c("Fit Price [preProc]", "Opponent Price [preProc]")) +
    ggtitle(label = 'Preprocessed Fit Price and Opponent Price\nagainst the outcome')
```

This plot shows, that both preprocessed predictors have a nonlinear relationship to the
outcome, so they are modelled as polynomials of grade 3.

```{r warning=FALSE, message=FALSE}
repCVControl <- trainControl(method = 'repeatedcv', number = 10, 
                             repeats = 3)
set.seed(1)
# ordinary linear regression
lmPreProcFit <- train(kickerGrade ~ poly(preProcFitPrice, 3) + 
                          poly(preProcOpponentPrice, 3) +
                          home + transPos, data = modelData,
                      method = 'lm', trControl = repCVControl)
lmPreProcFit

residPlot1 <- modelData %>% ggplot(aes(y = kickerGrade, x = predict(lmPreProcFit, modelData))) +
    geom_smooth() +
    coord_fixed(ratio = 1, xlim = c(2, 5), ylim = c(2, 5)) +
    scale_x_continuous(name = 'Predicted') +
    scale_y_continuous(name = 'Observed') +
    geom_abline(intercept = 0, slope = 1, size = 0.2, linetype = 'dashed')

residPlot2 <- modelData %>% ggplot(aes(y = resid(lmPreProcFit), x = predict(lmPreProcFit, modelData))) +
    geom_smooth() +
    scale_x_continuous(name = 'Predicted') +
    scale_y_continuous(name = 'Residual') +
    geom_hline(size = 0.2, linetype = 'dashed')

library(grid)
library(gridExtra)
grid.arrange(residPlot1, residPlot2, ncol = 2, main = "Residual Plots")
```

Although the residual plots show very poor performance for predicted values below a value of 3, we stick to this model for now. A nonlinear modelling approach should be tried here, this task is on the TODO list.

```{r warning=FALSE, message=FALSE}
enrichedStats <- enrichAdjGrade(adjGradeData)

# Merges adjusted grade in stats
mergedStats <- merge(stats, select(
    enrichedStats, matchId, playerId, adjGrade),
    by = c('matchId', 'playerId'),  all.x = TRUE)
summary(mergedStats$adjGrade)
```

The adjusted grade is calculated by subtracting the achieved kicker grade by the estimated grade predicted by the model. The bigger the value for adjGrade, the better the performance of the regarded player in the associated match.

## Enrich stats by an estimated form value for the upcoming match

In the next step the before calculated adjusted grades are used to estimate a form parameter for every player in each upcoming match. To acomplish a valid form parameter, an arima time series analysis is performed, the past performances, represented in the adjusted grade, are passed to the time series analysis to predict the performance for the upcoming match. There have to be at least 5 past matches to make a form calculation possible. Matches in which the regarded player did not participate or in which he sit on the bench are imputed with a static value.

```{r warning=FALSE, message=FALSE}
source(file = 'formModel.R', echo = FALSE, encoding = 'UTF-8')
formEnrichedPlayerStats <- enrichForm(mergedStats, matches, 'arima', minMatchdays = 5, imputeBenchBy = -0.05, imputeNotPlayedBy = -0.25)
summary(formEnrichedPlayerStats$playerForm)
```

## Feature extraction for the final models

The player prices and form parameters are teamwise averaged. The resulting dataset contains matches as observations with the features homePrice, visitorsPrice, homeForm and visitorsForm.

```{r warning=FALSE, message=FALSE}
source(file = 'simple/simpleResultFeatureExtraction.R', echo = FALSE, encoding = 'UTF-8')
featuredMatches <- simpleMatchFeatureExtract(
    formEnrichedPlayerStats, matches)
# Replace NANs with NAs
featuredMatches[is.nan(featuredMatches$homeForm), 'homeForm'] <- NA
featuredMatches[is.nan(featuredMatches$visitorsForm), 'visitorsForm'] <- NA
```

These predictors by themselfs are not very meaningful, so they are transformed to reflect the relation of the home team to the visitors team.

```{r warning=FALSE, message=FALSE}
modelData <- featuredMatches %>% filter(!is.na(homePrice), !is.na(visitorsPrice),
                                  !is.na(homeForm), !is.na(visitorsForm))
modelData <- modelData %>% mutate(priceDiff = homePrice - visitorsPrice,
                                  logPriceRate = log(homePrice / visitorsPrice),
                                  formDiff = homeForm - visitorsForm)

library(psych)
describe(select(modelData, homePrice, visitorsPrice, homeForm, visitorsForm,
                priceDiff, logPriceRate, formDiff))

p1 <- modelData %>% ggplot(aes(y = goalDiff, x = priceDiff)) +
    geom_smooth()
p2 <- modelData %>% ggplot(aes(y = goalDiff, x = logPriceRate)) +
    geom_smooth()
p3 <- modelData %>% ggplot(aes(y = goalDiff, x = formDiff)) +
    geom_smooth()
grid.arrange(p1, p2, p3, ncol = 2, main = "feature vs. goalDiff")
```

## Fitting final models

To predict the probabilities of the three possible outcomes (home victory, draw, visitors victory), a two step approach is implemented.
First, the goal difference (home - visitors) is estimated by the three predictors *priceDiff*, *logPriceRate* and *formDiff*. In the second step, the categorical match result is estimated by the estimated goal difference, predicted by the first model.

First the data is split in three parts:
1. Train set for the goal difference model (40% of the data)
2. Train set for the result model (40% of the data)
3. Test set to evaluate the predictions against the booky predictions (20% of the data)

```{r warning=FALSE, message=FALSE}
set.seed(1)
testIndex <- createDataPartition(modelData$goalDiff, p = 0.2,
                                 list = FALSE,
                                 times = 1)
test <- modelData[ testIndex, ]
train <- modelData[ -testIndex, ]
goalDiffTrainIndex <- createDataPartition(train$goalDiff, p = 0.5,
                                          list = FALSE,
                                          times = 1)
goalDiffTrain <- train[ goalDiffTrainIndex, ]
resultTrain <- train[ -goalDiffTrainIndex, ]
```

### Fitting Goal Difference Model

We first fit a linear model:

```{r warning=FALSE, message=FALSE}
set.seed(1)
lmGoalDiffFit <- train(goalDiff ~ priceDiff + logPriceRate + formDiff, method = 'lm',
               data = goalDiffTrain, trControl = repCVControl)
summary(lmGoalDiffFit)
```

```{r warning=FALSE, message=FALSE, echo=FALSE}
residPlot1 <- goalDiffTrain %>% ggplot(aes(y = goalDiff, x = predict(lmGoalDiffFit, goalDiffTrain))) +
    geom_point() +
    geom_smooth() +
    coord_fixed(ratio = 1, xlim = c(-2.5, 3), ylim = c(-2.5, 3)) +
    scale_x_continuous(name = 'Predicted') +
    scale_y_continuous(name = 'Observed') +
    geom_abline(intercept = 0, slope = 1, size = 0.2, linetype = 'dashed')

residPlot2 <- goalDiffTrain %>% ggplot(aes(y = resid(lmGoalDiffFit), 
                                           x = predict(lmGoalDiffFit, goalDiffTrain))) +
    geom_point() +
    geom_smooth() +
    scale_x_continuous(name = 'Predicted') +
    scale_y_continuous(name = 'Residual') +
    geom_hline(size = 0.2, linetype = 'dashed')

grid.arrange(residPlot1, residPlot2, ncol = 2, main = "Residual Plots")
```

Although the residual plots show, that a linear model is suitable for the data, we additionally fit a neural network and a multivariate adaptive regression spline model (not shown here). But in terms of R^2 and RMSE the linear model outperforms the other two models.

### Fitting Result Model

The second stop fits a categorical model to predict the match outcome by the estimated goal difference. I chose a ordered logistic regression (polr), because it is the only model I know which takes an ordered categorical outcome into consideration.

```{r warning=FALSE, message=FALSE}
resultModelInput <- resultTrain %>% mutate(goalDiffPred = predict(lmGoalDiffFit, resultTrain))
set.seed(1)
polrFit <- train(matchResult ~ goalDiffPred, method = 'polr', data = resultModelInput, trControl = repCVControl)
polrFit
```

